{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2edbd0e1",
   "metadata": {},
   "source": [
    "## Notebook to to convert cell data to pseudobulk based on broad cell-types ('curated_type') and cluster specific cell-types ('cluster_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d370583",
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b70488",
   "metadata": {},
   "source": [
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30831d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anndata import AnnData\n",
    "from pandas import DataFrame as PandasDF, concat\n",
    "from polars import read_parquet, DataFrame as PolarsDF, col as pl_col\n",
    "import scanpy as sc\n",
    "from matplotlib.pyplot import rc_context\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from multiprocessing import Process\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import random\n",
    "random.seed(420)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07565981-9394-4049-8b1f-bbc445837762",
   "metadata": {},
   "source": [
    "#### set notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcba3f5-57ee-4a76-9688-1978b45a6842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "modality = 'GEX' # 'GEX' or 'ATAC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d7aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming\n",
    "project = 'aging_phase2'\n",
    "\n",
    "# directories\n",
    "wrk_dir = '/labshare/raph/datasets/adrd_neuro/brain_aging/phase2'\n",
    "quants_dir = f'{wrk_dir}/quants'\n",
    "results_dir = f'{wrk_dir}/results'\n",
    "figures_dir = f'{wrk_dir}/figures'\n",
    "sc.settings.figdir = f'{figures_dir}/'\n",
    "\n",
    "# in files\n",
    "anndata_file = f'{quants_dir}/{project}.multivi.curated.h5ad'\n",
    "if modality == 'GEX':\n",
    "    quants_file = f'{quants_dir}/{project}.multivi_norm_exp.parquet'\n",
    "elif modality == 'ATAC':\n",
    "    quants_file = f'{quants_dir}/{project}.multivi_peak_est.parquet'    \n",
    "\n",
    "# out files\n",
    "\n",
    "# variables\n",
    "DEBUG = False\n",
    "TESTING = False\n",
    "TEST_FEATURE_SIZE = 1000\n",
    "categories = ['curated_type', 'cluster_name'] # 'curated_type' for broad and 'cluster_name' for specific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f30ba4",
   "metadata": {},
   "source": [
    "#### analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90886c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_data(adata: AnnData, quants: PolarsDF, cell_name: str, obs_col: str, \n",
    "                reapply_filter: bool=True, min_cell_count: int=3, \n",
    "                verbose: bool=False) -> tuple[PandasDF, PolarsDF]:\n",
    "    sub_adata = adata[(adata.obs[obs_col] == cell_name)].copy()\n",
    "    if reapply_filter:\n",
    "        sc.pp.filter_genes(sub_adata, min_counts=min_cell_count)\n",
    "        sc.pp.filter_cells(sub_adata, min_counts=min_cell_count)\n",
    "    # now that have subset of anndata, grab the same cells and features from the separate data matrix\n",
    "    features = list(sub_adata.var.index.values)\n",
    "    # if no features left nothing to convert\n",
    "    if len(features) == 0:\n",
    "        return None, None\n",
    "    features.append('barcode')\n",
    "    sub_quants = (quants.select(features)\n",
    "                  .filter(pl_col('barcode').is_in(sub_adata.obs.index.values)))\n",
    "    return sub_adata.obs, sub_quants\n",
    "\n",
    "def scale_dataframe(this_df : PolarsDF) -> PandasDF:\n",
    "    scaledX = MinMaxScaler().fit_transform(this_df.drop('barcode').to_pandas())\n",
    "    scaled_df = PandasDF(data=scaledX, columns=this_df.drop('barcode').columns, \n",
    "                         index=this_df['barcode'])\n",
    "    return scaled_df \n",
    "\n",
    "def feature_detected(feature_col, features: list=None, df: PandasDF=None,\n",
    "                     min_cell_count: int=3, min_sample_det_rate: float=0.5,\n",
    "                     verbose: bool=False):\n",
    "    if feature_col.name not in features:\n",
    "        return False  # Early exit for efficiency\n",
    "    nz_df = feature_col[feature_col > 0]\n",
    "    if len(nz_df) < min_cell_count:\n",
    "        return False  # Early exit if insufficient non-zero cells\n",
    "    ok_sample_cnt = (df.loc[nz_df.index, 'sample_id'].value_counts() >= min_cell_count).sum()\n",
    "    unique_sample_id_count = df['sample_id'].nunique()\n",
    "    good_feature = ok_sample_cnt / unique_sample_id_count >= min_sample_det_rate\n",
    "    if verbose:\n",
    "        print((f'{feature_col.name}, nz_df.shape={nz_df.shape}, '\n",
    "               f'{ok_sample_cnt}/{unique_sample_id_count}, {good_feature}'))\n",
    "    return good_feature\n",
    "\n",
    "def remove_poorly_detected_features(features: list=None, df: PandasDF=None, \n",
    "                                    info_df: PandasDF=None, verbose=False) -> PandasDF:\n",
    "    if df.index.equals(info_df.index):\n",
    "        df = concat([df, info_df['sample_id']], axis='columns')\n",
    "    else:\n",
    "        print('indices unequal could not add sample_id column')\n",
    "        return\n",
    "    feature_detect_df = df.apply(feature_detected, features=features, df=df)\n",
    "    bad_features = feature_detect_df.loc[~feature_detect_df].index.to_list()\n",
    "    if verbose:\n",
    "        print(f'bad features counts is {len(bad_features)}')\n",
    "    return df.drop(columns=bad_features)\n",
    "\n",
    "def compute_frmt_pb(df: PandasDF=None, \n",
    "                    info_df: PandasDF=None) -> tuple[PandasDF, PandasDF]:\n",
    "    if df.index.equals(info_df.index):\n",
    "        df = concat([df, info_df['sample_id']], axis='columns')\n",
    "    else:\n",
    "        print('indices unequal could not add sample_id column')\n",
    "        return    \n",
    "    ret_df = df.groupby('sample_id').mean()\n",
    "    ret_df['cell_count'] = df.sample_id.value_counts()\n",
    "    return ret_df\n",
    "\n",
    "def pseudobulk_conversion(quants: PolarsDF, info_df: PolarsDF, cell_name: str, \n",
    "                          features: list, category: str):\n",
    "    # minmax scale the subset\n",
    "    quants = scale_dataframe(quants)\n",
    "    # drop any poorly detected features across samples\n",
    "    quants = remove_poorly_detected_features(features, quants, info_df)\n",
    "    pseudo_bulk = compute_frmt_pb(quants, info_df)\n",
    "    # save the pseudo bulk data for the cell-type\n",
    "    save_results(pseudo_bulk, cell_name, category)\n",
    "    \n",
    "def save_results(df: PandasDF, cell_name: str, category: str):\n",
    "    if category == 'curated_type':\n",
    "        prefix_type = 'broad'\n",
    "    elif category == 'cluster_name':\n",
    "        prefix_type = 'specific'    \n",
    "    out_file = f'{quants_dir}/{project}.{modality}.{prefix_type}.{cell_name}.pb.parquet'\n",
    "    df.to_parquet(out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0761635d",
   "metadata": {},
   "source": [
    "\n",
    "### load data\n",
    "read the anndata (h5ad) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996604d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adata = sc.read(anndata_file, cache=True)\n",
    "print(adata)\n",
    "if DEBUG:\n",
    "    display(adata.obs.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89d99c1-e8df-4f6a-b089-80bb7b008120",
   "metadata": {},
   "source": [
    "### subset feature set by modality (GEX or ATAc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e745e8d0-ff93-4aa6-8b37-88e166cdc0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if modality == 'GEX':\n",
    "    features = list(adata.var.loc[adata.var.modality == 'Gene Expression'].index.values)\n",
    "elif modality == 'ATAC':\n",
    "    features = list(adata.var.loc[adata.var.modality == 'Peaks'].index.values)\n",
    "adata = adata[:,features]\n",
    "print(adata)\n",
    "display(adata.var.modality.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20212b83",
   "metadata": {},
   "source": [
    "#### take a look at the cell counts by cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    display(adata.obs[category].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e59b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    with rc_context({'figure.figsize': (9, 9)}):\n",
    "        sc.pl.umap(adata, color=[category], legend_loc='on data', \n",
    "                   add_outline=True, legend_fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d54b70-0136-484d-abb7-4c80e58cac49",
   "metadata": {},
   "source": [
    "### load the quantfied features\n",
    "either expression (GEX) and chromatin accessibiltiy (ATAT) base on the modality that was specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1030e2-e21f-492c-b6f7-dabf5d566b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "quants_df = read_parquet(quants_file)\n",
    "# for a polars dataframe read from parquent need to fix index column name\n",
    "quants_df = quants_df.rename({'__index_level_0__': 'barcode'})\n",
    "print(f'shape of quantified {modality} features: {quants_df.shape}')\n",
    "if DEBUG:\n",
    "    display(quants_df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf42aef",
   "metadata": {},
   "source": [
    "### if testing notebooks for debugging purpose subset the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227c7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TESTING:\n",
    "    if modality == 'GEX':\n",
    "        features = random.sample(list(adata.var.loc[adata.var.modality == 'Gene Expression'].index.values),\n",
    "                                 TEST_FEATURE_SIZE)\n",
    "    elif modality == 'ATAC':\n",
    "        features = random.sample(list(adata.var.loc[adata.var.modality == 'Peaks'].index.values),\n",
    "                                 TEST_FEATURE_SIZE)\n",
    "    adata = adata[:,features]\n",
    "    # need to keep the barcode as well\n",
    "    features.append('barcode')    \n",
    "    quants_df = quants_df.select(features)\n",
    "    print(adata)\n",
    "    display(adata.var.modality.value_counts())\n",
    "    print(f'shape of testing quants dataframe is: {quants_df.shape}')\n",
    "    display(quants_df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8cf910",
   "metadata": {},
   "source": [
    "### for each cell-type pseudobulk (mean) convert the the single-cell quantifications\n",
    "\n",
    "parallelized by cell-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a099ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for category in categories:\n",
    "    print(f'#### processing {category}')\n",
    "    cmds = {}\n",
    "    for cell_type in adata.obs[category].unique():\n",
    "        print(f'--- {cell_type}')\n",
    "        # subset by cell-type or cluster\n",
    "        obs_sub, quants_sub = subset_data(adata, quants_df, cell_type, category)\n",
    "        if quants_sub is None:\n",
    "            print(f'{cell_type} is empty, skipping')\n",
    "            continue\n",
    "        # pseudobulk_conversion(quants_sub, obs_sub, cell_type, list(adata.var.index.values), category)\n",
    "        p = Process(target=pseudobulk_conversion,args=(quants_sub, obs_sub, \n",
    "                                                       cell_type, list(adata.var.index.values),\n",
    "                                                       category))\n",
    "        p.start()\n",
    "        # Append process and key to keep track\n",
    "        cmds[cell_type] = p    \n",
    "        # diffexp_group(adata_sub, cell_name)\n",
    "    # Wait for all processes to finish\n",
    "    for key, p in cmds.items():\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ade5b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
