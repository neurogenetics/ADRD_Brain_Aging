{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "081c2ebf-d5d8-437c-9a4e-15ac49ce2030",
   "metadata": {},
   "source": [
    "## Using the multiVI latent representations predicted the cell-types for the ATAC cells using the RNA cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea113c-91ba-46bc-9512-bc84569100ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f05fa4-44e4-44a1-b469-3e6fb96664d8",
   "metadata": {},
   "source": [
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c81e43-81cb-446b-be75-6b253a2c20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvi\n",
    "import scanpy as sc\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import torch\n",
    "from anndata import AnnData\n",
    "from pandas import DataFrame, concat, Series\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import rc_context\n",
    "from seaborn import barplot\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "scvi.settings.seed = 42\n",
    "\n",
    "%matplotlib inline\n",
    "# for white background of figures (only for docs rendering)\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032ee3f9-36f8-4315-832d-ff075f31b64b",
   "metadata": {},
   "source": [
    "#### set notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a1806-beac-45f5-ae1e-351bed49f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables and constants\n",
    "project = 'aging_phase2'\n",
    "DEBUG = True\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "MODEL_QUAL_PRESET = 'good'\n",
    "\n",
    "# directories\n",
    "wrk_dir = '/labshare/raph/datasets/adrd_neuro/brain_aging/phase2'\n",
    "quants_dir = f'{wrk_dir}/quants'\n",
    "models_dir = f'{wrk_dir}/models'\n",
    "figures_dir = f'{wrk_dir}/figures'\n",
    "sc.settings.figdir = f'{figures_dir}/'\n",
    "\n",
    "# in files\n",
    "in_h5ad_file = f'{quants_dir}/{project}.dev.multivi.h5ad'\n",
    "\n",
    "# out files\n",
    "out_h5ad_file = f'{quants_dir}/{project}.dev.multivi.annotated.h5ad'\n",
    "trained_model_path = f'{models_dir}/{project}_dev_trained_cellpred'\n",
    "\n",
    "if DEBUG:\n",
    "    print(f'{in_h5ad_file=}')\n",
    "    print(f'{out_h5ad_file=}')\n",
    "    print(f'{trained_model_path=}')\n",
    "    print(f'{device=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a96e7a5-3f8c-424f-8d30-279f07a784b7",
   "metadata": {},
   "source": [
    "#### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0128c9ff-14ce-401e-a2b8-94e29d26c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peek_anndata(adata: AnnData, message: str=None, verbose: bool=False):\n",
    "    if not message is None and len(message) > 0:\n",
    "        print(message)\n",
    "    print(adata)\n",
    "    if verbose:\n",
    "        display(adata.obs.head())\n",
    "        display(adata.var.head())\n",
    "\n",
    "def peek_dataframe(df: DataFrame, message: str=None, verbose: bool=False):\n",
    "    if not message is None and len(message) > 0:\n",
    "        print(message)\n",
    "    print(f'{df.shape=}')\n",
    "    if verbose:\n",
    "        display(df.head())\n",
    "\n",
    "def eval_classifier_model(model: TabularPredictor, this_data: TabularDataset, \n",
    "                          target: str, verbose: bool=False) -> (Series, DataFrame):\n",
    "\n",
    "    x_pred = model.predict(this_data)\n",
    "    eval_results = model.evaluate_predictions(this_data[target], x_pred, \n",
    "                                              detailed_report=True)\n",
    "    print(f'## {target=} {eval_results.get('accuracy')=}')\n",
    "    print(f'## {target=} {eval_results.get('balanced_accuracy')=}')\n",
    "    print(f'## {target=} Matthews Correlation Coefficient: {eval_results.get('mcc')}')\n",
    "    ret_df = (DataFrame(eval_results.get('classification_report')).transpose()\n",
    "              .sort_values('f1-score', ascending=False))\n",
    "    ret_df['cell_type'] = ret_df.index.values\n",
    "    ret_df = ret_df.loc[~ret_df.cell_type.isin(['accuracy', 'macro avg', \n",
    "                                                'weighted avg'])].reset_index(drop=True)    \n",
    "    if verbose:\n",
    "        display(this_data[target].value_counts())\n",
    "        display(x_pred.value_counts())\n",
    "        display(ret_df)\n",
    "    return x_pred, ret_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102419fb-a1ea-491b-a554-6b19ef9665e6",
   "metadata": {},
   "source": [
    "## load the multiVI latent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96540d8b-18e9-4438-8a2e-ac5d59d83e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(in_h5ad_file)\n",
    "peek_anndata(adata, 'loaded the multiVI anndata', DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7966af-086e-4c59-9a1e-cb3082c2d467",
   "metadata": {},
   "source": [
    "## split the anndata into training, test, and inference datasets\n",
    "\n",
    "here will use the GEX and ARC for train/test, and ATAC for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9ba633-da66-4d23-b264-00e3b7320e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train_test = adata[adata.obs.modality.isin(['expression', 'paired'])]\n",
    "adata_infer = adata[adata.obs.modality == 'accessibility']\n",
    "\n",
    "train_test_data = TabularDataset(adata_train_test.obsm['MultiVI_latent'])\n",
    "train_test_data['cell_label'] = adata_train_test.obs.cell_label.values\n",
    "train_test_data.index = adata_train_test.obs.index.values\n",
    "\n",
    "inference_data = TabularDataset(adata_infer.obsm['MultiVI_latent'])\n",
    "inference_data['cell_label'] = adata_infer.obs.cell_label.values\n",
    "inference_data.index = adata_infer.obs.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fd728e-b161-4c9a-acf2-f937cc259431",
   "metadata": {},
   "source": [
    "### split the train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3728b1ca-666b-44b9-99c5-81b5cb20bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_test_data.drop(columns=['cell_label']), \n",
    "                                                    train_test_data['cell_label'], \n",
    "                                                    stratify=train_test_data['cell_label'],\n",
    "                                                    test_size=0.3, random_state=42)\n",
    "train_data = train_test_data.loc[X_train.index]\n",
    "test_data = train_test_data.loc[X_test.index]\n",
    "\n",
    "# make sure there are not any unlabeled cells in the train and test\n",
    "train_data = train_data.loc[train_data.cell_label != 'Unknown']\n",
    "test_data = test_data.loc[test_data.cell_label != 'Unknown']\n",
    "\n",
    "peek_dataframe(train_data, 'training dataframe', DEBUG)\n",
    "peek_dataframe(test_data, 'testing dataframe', DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b986d293-c439-4615-ba49-2bd47d0e2e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    display(train_data.cell_label.value_counts())\n",
    "    display(test_data.cell_label.value_counts())\n",
    "    display(inference_data.cell_label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299866fb-fced-4dec-994d-5fa3fcbf3eac",
   "metadata": {},
   "source": [
    "#### how many of the test split are ARC samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ea7c4-60dc-4244-ab52-2f97805701cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_temp = adata[adata.obs.modality == 'paired'].obs\n",
    "display(arc_temp.modality.value_counts())\n",
    "print(f'{arc_temp.shape=}')\n",
    "print(f'{test_data.shape=}')\n",
    "print(len(set(test_data.index) & set(arc_temp.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3f171d-af31-48aa-9fdb-e74ba91c8e3a",
   "metadata": {},
   "source": [
    "## use autoML to train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383e6f32-7195-4843-8552-84e05455a603",
   "metadata": {},
   "source": [
    "### initialize a AutoGluon Tabular Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d570e954-1f27-4557-9563-ecf0b8285775",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TabularPredictor(label='cell_label', path=trained_model_path, \n",
    "                             verbosity=2, log_to_file=True, eval_metric='mcc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e76c1e-b4a8-4363-a9cf-14b58add6bc1",
   "metadata": {},
   "source": [
    "### train the predictor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e673514f-e8fc-4956-8807-9a15ab146a60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "predictor.fit(train_data, presets=MODEL_QUAL_PRESET, num_gpus=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f65a7ba-9aa0-4650-bc16-077ee2835cfb",
   "metadata": {},
   "source": [
    "### train data eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6905311f-e4a6-4998-bf8e-6a7e82ecf7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var = 'cell_label'\n",
    "train_predictions, train_scores = eval_classifier_model(predictor, train_data, target_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba9caae-979c-4cf1-9c9d-b1d10f2fb7dd",
   "metadata": {},
   "source": [
    "### test data eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce62853-54ec-4d48-a633-054b0dc1aed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions, test_scores = eval_classifier_model(predictor, test_data, target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca1d87b-387e-4f67-98fa-2c081ad9de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    display(train_scores)\n",
    "    display(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad4a3e-2c49-485c-b519-1a76c618cfa2",
   "metadata": {},
   "source": [
    "### visualize the eval data for train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1d4ff8-0afa-4325-b664-bf42a3f47e5b",
   "metadata": {},
   "source": [
    "### individual model scores for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943e181e-3ab2-48dd-9aef-724d3b0e5f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores['dataset'] = 'train'\n",
    "test_scores['dataset'] = 'test'\n",
    "scores_df = concat([test_scores, train_scores])\n",
    "with rc_context({'figure.figsize': (8, 8), 'figure.dpi': 100}):\n",
    "    plt.style.use('seaborn-v0_8-talk')\n",
    "    barplot(data=scores_df, x='cell_type', y='f1-score', hue='dataset', palette='colorblind')\n",
    "    plt.legend(title='dataset', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel('Cell Types')\n",
    "    plt.ylabel('F1 Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a8651f-261c-436b-b49f-6d63eced4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{predictor.model_best=}')\n",
    "if DEBUG:\n",
    "    display(predictor.leaderboard())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d02bc5-0f11-4412-bc41-17794490426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    display(train_data.cell_label.value_counts())\n",
    "    display(test_data.cell_label.value_counts())\n",
    "    display(test_predictions.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5230cee9-32eb-4072-8d39-f9ced42f8363",
   "metadata": {},
   "source": [
    "## infer the cell labels for the unknown cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e60234f-729c-4fd2-a54b-4cb2bcde7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "atac_labels = predictor.predict(inference_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f2a551-cd8f-4a71-bca9-97057efc3967",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    display(train_data.cell_label.value_counts())\n",
    "    display(test_data.cell_label.value_counts())\n",
    "    display(atac_labels.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892df97b-4b2d-4301-8cd7-6ac24ecb3ba0",
   "metadata": {},
   "source": [
    "### visualize the number of cells by cell-types for each of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51632e-5e88-4087-bbec-300384d55b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_counts = concat([train_data.cell_label.value_counts(), \n",
    "                           test_data.cell_label.value_counts(), \n",
    "                           atac_labels.value_counts()], axis='columns')\n",
    "combined_counts.columns = ['Train', 'Test', 'Inference']\n",
    "combined_counts = combined_counts.reset_index()\n",
    "combined_counts = combined_counts.melt(id_vars=['cell_label'], \n",
    "                                       value_vars=['Train', 'Test', 'Inference'], \n",
    "                                       var_name='Dataset', value_name='Cell_counts')\n",
    "with rc_context({'figure.figsize': (8, 8), 'figure.dpi': 100}):\n",
    "    plt.style.use('seaborn-v0_8-talk')\n",
    "    barplot(data=combined_counts, x='cell_label', y='Cell_counts', hue='Dataset', palette='colorblind')\n",
    "    plt.legend(title='Dataset', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel('Cell Types')\n",
    "    plt.ylabel('Cell Counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a520f5f-6d94-47ed-94ea-4150cce6b4b6",
   "metadata": {},
   "source": [
    "### for the test dataset what are the important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19410fc-e1e4-4a0a-8227-7ffd0d0df11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# feat_imp = predictor.feature_importance(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3acd98-f3e6-41c6-9fcf-1c4b345c2b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
