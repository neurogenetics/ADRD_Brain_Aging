{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "798eebf4-d9ab-445d-9b4e-d6c8be326f06",
   "metadata": {},
   "source": [
    "## Notebook to prepare the input files from the replication data for analysis with glmmTMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf3d82-1fcd-4506-b113-c716b18c4113",
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6c1634-f53b-4158-8007-73c7b2911193",
   "metadata": {},
   "source": [
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106b96ef-19ca-4114-8a51-5db5bb82648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "from os.path import exists\n",
    "from pandas import DataFrame, concat, read_csv\n",
    "from anndata import AnnData\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import rc_context\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from polars import read_csv as pl_read_csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from multiprocessing import Process\n",
    "\n",
    "# for white background of figures (only for docs rendering)\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7911a7b7-3a36-4659-bc49-8db756b64cfd",
   "metadata": {},
   "source": [
    "#### set notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a533d8-1028-4a80-a630-081951c7fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming\n",
    "project = 'aging_phase1'\n",
    "set_name = f'{project}_replication'\n",
    "\n",
    "# directories\n",
    "wrk_dir = '/labshare/raph/datasets/adrd_neuro/brain_aging/phase1'\n",
    "replication_dir = f'{wrk_dir}/replication'\n",
    "quants_dir = f'{wrk_dir}/demux'\n",
    "results_dir = f'{wrk_dir}/results'\n",
    "figures_dir = f'{wrk_dir}/figures'\n",
    "sc.settings.figdir = f'{figures_dir}/'\n",
    "\n",
    "# in files\n",
    "anndata_file = f'{replication_dir}/{set_name}.scvi.h5ad'\n",
    "temp_name_remap_json = '{this_dir}/{name}_gene_name_remap_temp.csv'\n",
    "temp_r_out_file = '{this_dir}/aging.{name}_glmmtmb_results_temp.csv'\n",
    "\n",
    "# out files\n",
    "temp_r_in_file = '{this_dir}/{name}_glmmtmb_in_df_temp.csv'\n",
    "\n",
    "\n",
    "# variables\n",
    "DEBUG = True\n",
    "REGIONS = ['Middle_temporal_gyrus', 'Putamen', \n",
    "           'Entorhinal_cortex', 'Subventricular_zone']\n",
    "CELLTYPES=['ExN', 'Oligodendrocyte', 'Astrocyte', 'InN', 'OPC', 'Mural', \n",
    "           'Microglia', 'SPN', 'Endothelial', 'Ependymal']\n",
    "cell_abbr_mappings = {'ExN': 'ExN', 'Oligodendrocyte': 'Oligo', 'Astrocyte': 'Astro', \n",
    "                      'InN': 'InN', 'OPC': 'OPC', 'Microglia': 'Micro', 'Endothelial': 'Endo'}\n",
    "MAX_ALPHA = 0.05\n",
    "SCVI_NORMALIZED_KEY = 'scvi_normalized'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465f8c56-c8f8-4513-b2c0-0af5d3ea5466",
   "metadata": {},
   "source": [
    "#### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa91a4-e7e0-443a-860d-631d921a8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_feature_renamed_map(cell_name: str) -> dict:\n",
    "    # read dict from json file\n",
    "    rename_cols = json.load(open(temp_name_remap_json.format(this_dir=quants_dir,\n",
    "                                                             name=cell_name.replace(\" \", \"_\"))))\n",
    "    return rename_cols\n",
    "\n",
    "def reformat_glmmtmb_df(df: DataFrame) -> DataFrame:\n",
    "    # reformat results into one row per feature\n",
    "    temp_term = df.loc[df['term'] == 'old'].copy()\n",
    "    temp_intercepts = df.loc[df['term'] == '(Intercept)', ['feature', 'estimate']].copy()\n",
    "    temp_intercepts = temp_intercepts.rename(columns={'estimate': 'intercept'})\n",
    "    this_df = temp_term.merge(temp_intercepts, how='inner', on='feature')\n",
    "    return this_df[['feature', 'intercept', 'estimate', 'std.error', 'statistic', 'p.value']]\n",
    "\n",
    "def read_glmmtmb_results(cell_name: str, group_type: str, cols_to_rename: dict) -> DataFrame:\n",
    "    this_file = temp_r_out_file.format(this_dir=f'{results_dir}',\n",
    "                                       name=cell_name.replace(\" \", \"_\"))\n",
    "    this_df = read_csv(this_file)\n",
    "    # need to flip the features with '-' -> '_' for R back to originals\n",
    "    # the the key/values\n",
    "    rename_cols = {value: key for (key, value) in cols_to_rename.items()}\n",
    "    this_df['feature'] = this_df['feature'].replace(rename_cols)\n",
    "    this_df = reformat_glmmtmb_df(this_df)\n",
    "    this_df['tissue'] = cell_name\n",
    "    this_df['type'] = group_type     \n",
    "    return this_df\n",
    "\n",
    "def compute_bh_fdr(df: DataFrame, alpha: float=0.05, p_col: str='p.value',\n",
    "                   method: str='fdr_bh', verbose: bool=True) -> DataFrame:\n",
    "    ret_df = df.copy()\n",
    "    test_adjust = multipletests(np.array(ret_df[p_col]), alpha=alpha, method=method)\n",
    "    ret_df[method] = test_adjust[1]\n",
    "    if verbose:\n",
    "        print(f'total significant after correction: {ret_df.loc[ret_df[method] < alpha].shape}')\n",
    "    return ret_df\n",
    "\n",
    "def subset_anndata(data: AnnData, cell_name: str, features: list, reapply_filter: bool=True, \n",
    "                   min_cell_count: int=3, verbose: bool=False) -> AnnData:\n",
    "    this_data = data[(data.obs.Cell_type == cell_name),features].copy()\n",
    "    shape_before = this_data.shape\n",
    "    if reapply_filter:\n",
    "        sc.pp.filter_genes(this_data, min_counts=min_cell_count)\n",
    "        sc.pp.filter_cells(this_data, min_counts=min_cell_count)\n",
    "        shape_after = this_data.shape\n",
    "    if verbose:\n",
    "        print(f'subset complete, shape before and after: {shape_before} {shape_after}')\n",
    "        print(this_data)\n",
    "    return this_data\n",
    "\n",
    "def scale_dataframe(this_df : DataFrame):\n",
    "    scaledX = MinMaxScaler().fit_transform(this_df)\n",
    "    scaled_df = DataFrame(data=scaledX, columns=this_df.columns, \n",
    "                          index=this_df.index) \n",
    "    return scaled_df\n",
    "\n",
    "def convert_ad_to_df(data: AnnData, young_age_limit: float=30.0, \n",
    "                     scale: bool=True, verbose: bool=False) -> DataFrame:\n",
    "    data_df = data.to_df(SCVI_NORMALIZED_KEY)\n",
    "    if scale:\n",
    "        data_df = scale_dataframe(data_df)       \n",
    "    annots = data.obs[['Sample_ID', 'Age','Sex']].copy()\n",
    "    annots['old'] = np.where((annots['Age'] > young_age_limit), 1, 0)\n",
    "    annots['female'] = np.where((annots['Sex'] == 'Female'), 1, 0)\n",
    "    this_df = None\n",
    "    if data_df.index.equals(annots.index):\n",
    "        this_df = concat([data_df, annots], axis='columns')\n",
    "        this_df.index.name = 'barcodekey'\n",
    "        if verbose:\n",
    "            print(f'anndata to pandas df complete: {this_df.shape}')\n",
    "            print(this_df.shape)\n",
    "            display(this_df.head())\n",
    "    return this_df\n",
    "\n",
    "def feature_detected(feature_col, features: list=None, df: DataFrame=None, \n",
    "                     min_cell_count: int=3, min_sample_det_rate: float=0.5,\n",
    "                     verbose: bool=False):    \n",
    "    good_feature = True\n",
    "    if feature_col.name in features:\n",
    "        nz_df = feature_col[feature_col > 0]\n",
    "        ok_cnts = df.loc[nz_df.index].Sample_ID.value_counts() > min_cell_count\n",
    "        ok_sample_cnt = ok_cnts.sum()\n",
    "        unique_sample_id_count = df.Sample_ID.nunique()\n",
    "        good_feature = ok_sample_cnt / unique_sample_id_count >= min_sample_det_rate\n",
    "        if verbose:\n",
    "            print(feature_col.name, end=', ')\n",
    "            print(f'nz_df.shape = {nz_df.shape}', end=', ')\n",
    "            print(f'{ok_sample_cnt}/{unique_sample_id_count}', end=', ')\n",
    "            print(good_feature)\n",
    "    return good_feature\n",
    "\n",
    "def poorly_detected_features(features: list=None, df: DataFrame=None, \n",
    "                             verbose=False) -> list:\n",
    "    feature_detect_df = df.apply(feature_detected, features=features, df=df)\n",
    "    bad_features = feature_detect_df.loc[~feature_detect_df].index.to_list()\n",
    "    if verbose:\n",
    "        print(f'bad features counts is {len(bad_features)}')\n",
    "    return bad_features\n",
    "\n",
    "def save_df_for_glmmtmb_in_r(df: DataFrame, cell_name: str):\n",
    "    # R doesn't like column names with hyphens in \n",
    "    # data frames when building formulas so replace temporarily\n",
    "    # find features containing hyphen\n",
    "    feats_w_hyphen = df.columns[df.columns.str.contains('-')]\n",
    "    # make dictionary to do replace\n",
    "    rename_cols = {x: x.replace('-', '_') for x in feats_w_hyphen}\n",
    "    df = df.rename(columns=rename_cols)\n",
    "    df.to_csv(temp_r_in_file.format(this_dir=f'{replication_dir}', \n",
    "                                    name=cell_name.replace(\" \", \"_\")))\n",
    "    # save to gene remame dict\n",
    "    json.dump(rename_cols, \n",
    "              open(temp_name_remap_json.format(this_dir=f'{replication_dir}',\n",
    "                                               name=cell_name.replace(\" \", \"_\")), 'w'))\n",
    "\n",
    "def diffexp_group(data: AnnData, cell_name: str,\n",
    "                  min_cell_count: int=3, \n",
    "                  verbose: bool=False) -> str:\n",
    "    type_ad = data\n",
    "    if verbose:\n",
    "        print('converting anndata to pandas df')    \n",
    "    type_df = convert_ad_to_df(data)\n",
    "    # find features poorly detected and don't include in analysis\n",
    "    if verbose:\n",
    "        print(f'finding poorly detected features from cells x features {type_df.shape}')    \n",
    "    bad_features = poorly_detected_features(data.var.index.values, type_df)\n",
    "    type_clean_df = type_df.drop(columns=bad_features)\n",
    "    keep_features = set(data.var.index) & set(type_clean_df.columns)\n",
    "    if verbose:\n",
    "        print(f'formatting glmmTMB command for {len(keep_features)} features and {type_clean_df.shape[0]} cells')    \n",
    "    this_cmd = save_df_for_glmmtmb_in_r(type_clean_df, cell_name)\n",
    "    print(f'\\ndone with {cell_name} kept {len(keep_features)} features and {type_clean_df.shape[0]} cells')\n",
    "    # if verbose:\n",
    "    #     print(f'done', end='. ')\n",
    "    return this_cmd\n",
    "\n",
    "def diffexp_group_wrapper(data: AnnData, cell_name: str):\n",
    "    diffexp_group(data, cell_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd4725d-856d-4bd1-89f8-40b6418106ef",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b9a0cd-079a-4f27-a36f-69525e1cabbd",
   "metadata": {},
   "source": [
    "#### load replication data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988e37b-7447-46f7-8cfb-04639056c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adata = sc.read(anndata_file, cache=True)\n",
    "print(adata)\n",
    "if DEBUG:\n",
    "    display(adata.obs.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd8612-f7a5-44c6-ad20-0b12d2a02183",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c05fd24-5813-4d7a-8ef5-e90df74e2678",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(adata.obs.Cell_type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53dee2-aa2e-40bb-a87a-293460fdd598",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(adata.obs.Sample_ID.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56c04db-e0be-409b-8649-9ec6c713cd83",
   "metadata": {},
   "source": [
    "#### load discovery results\n",
    "use this to determine which features in what cell-types need to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d0508-1b95-4ba7-9266-9420b34c18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "glmmtmb_results = None\n",
    "for region in REGIONS:\n",
    "    for cell_type in cell_abbr_mappings.keys():\n",
    "        print(region, cell_type)\n",
    "        in_results_file = f'{results_dir}/aging.{region}_{cell_type}_glmmtmb_results_temp.csv'\n",
    "        if exists(in_results_file):\n",
    "            this_tissue = f'{region}_{cell_type}'\n",
    "            renamed_features = read_feature_renamed_map(this_tissue)\n",
    "            glmmtmb_results = concat([glmmtmb_results, \n",
    "                                      read_glmmtmb_results(this_tissue, 'region_broad_type',\n",
    "                                                           renamed_features)])\n",
    "            print('Done.')\n",
    "        else:\n",
    "            print('Not found, skipping.')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749a85df-407f-42da-8067-656b6444c3b8",
   "metadata": {},
   "source": [
    "### compute the FDR values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c3ecc6-dfd3-49a8-b6b4-69ddc96fce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "glmmtmb_results['p.value'] = glmmtmb_results['p.value'].fillna(1)\n",
    "glmmtmb_results = compute_bh_fdr(glmmtmb_results)\n",
    "print(f'results shape is {glmmtmb_results.shape}')\n",
    "if DEBUG:\n",
    "    display(glmmtmb_results.sort_values('fdr_bh').head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1582d9-a1b3-4bda-8bf6-1c20edd05990",
   "metadata": {},
   "source": [
    "#### how many are 'nominally' significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db1cc0b-44d8-488c-82f1-a66045c57632",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_df = glmmtmb_results.loc[glmmtmb_results['p.value'] < MAX_ALPHA] \n",
    "print(nominal_df.shape)\n",
    "if DEBUG:\n",
    "    # see bottom of nominally significant\n",
    "    display(nominal_df.sort_values('p.value').tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9734d82-4614-4138-b409-e05b236ff1ce",
   "metadata": {},
   "source": [
    "#### count of significant genes by brain region cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd07456-be5a-4d22-9d2e-17972873a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "glmmtmb_results.loc[glmmtmb_results['fdr_bh'] < 0.05].tissue.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea770d30-a582-40a0-be4a-eb4ef8b9c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_df.tissue.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62611b2-01fd-48e8-979a-c2b0ba7702fc",
   "metadata": {},
   "source": [
    "### format the data for input to glmmTMB\n",
    "based on nominally significant results from discovery glmmTMB analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b29012b-d385-4882-bdbb-b84cab827361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for disc_cell_type, rep_cell_type in cell_abbr_mappings.items():\n",
    "#     cell_names = [f'{region}_{disc_cell_type}' for region in REGIONS]\n",
    "#     cell_name = f'Frontal_cortex_{rep_cell_type}'\n",
    "#     # subset the adata by cell-type and features\n",
    "#     features = nominal_df.loc[nominal_df.tissue.isin(cell_names)].feature.unique()\n",
    "#     if len(features) > 0:\n",
    "#         print(f'--- processing {cell_name} in parallel')\n",
    "#         features = list(set(features) & set(adata.var.index))\n",
    "#         adata_sub = subset_anndata(adata, rep_cell_type, features)\n",
    "#         diffexp_group(adata_sub, cell_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38127c82-73cd-41c9-a6e9-646f5441e828",
   "metadata": {},
   "source": [
    "based on all testable input for the discovery glmmTMB analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c47f81-22f9-4abb-ae5b-7324f4329ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cmds = {}\n",
    "for disc_cell_type, rep_cell_type in cell_abbr_mappings.items():\n",
    "    cell_names = [f'{region}_{disc_cell_type}' for region in REGIONS]\n",
    "    features = {}\n",
    "    for cell_name in cell_names:\n",
    "        in_file = temp_r_in_file.format(this_dir=quants_dir, name=cell_name)\n",
    "        glmm_in_df = pl_read_csv(in_file)\n",
    "        features = set(features) | set(glmm_in_df.columns)\n",
    "    # need to deal with hyphen to underscore revert\n",
    "    features = [st.replace('_', '-') for st in features]\n",
    "    features = list(set(features) & set(adata.var.index))\n",
    "    print(f'{rep_cell_type} might test {len(features)} features')\n",
    "    adata_sub = subset_anndata(adata, rep_cell_type, features)\n",
    "    cell_name = f'Frontal_cortex_{rep_cell_type}'\n",
    "    p = Process(target=diffexp_group_wrapper,args=(adata_sub, cell_name))\n",
    "    p.start()\n",
    "    # Append process and key to keep track\n",
    "    cmds[rep_cell_type] = p    \n",
    "    # diffexp_group(adata_sub, cell_name)\n",
    "# Wait for all processes to finish\n",
    "for key, p in cmds.items():\n",
    "    p.join()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25729d12-48b6-4472-abd7-641d58685391",
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m107"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
