{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2edbd0e1",
   "metadata": {},
   "source": [
    "## Notebook to run differential expression in single-cell data using GLM model and pseudo-bulk quantifications per sample\n",
    "\n",
    "based on some of the observations related to pseudo-replicate and zero-inflation from\n",
    "\n",
    "[Zimmerman KD, Espeland MA, Langefeld CD. A practical solution to pseudoreplication bias in single-cell studies. Nat Commun 2021;12:738.](https://pubmed.ncbi.nlm.nih.gov/33531494/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d370583",
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b70488",
   "metadata": {},
   "source": [
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30831d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anndata import AnnData\n",
    "import numpy as np\n",
    "from pandas import DataFrame, concat, read_csv\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import rc_context\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from numba import jit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from multiprocessing import Process\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import random\n",
    "random.seed(420)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd0d3dc-4363-4418-bac0-ce04f0b1dcbf",
   "metadata": {},
   "source": [
    "#### set notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d7aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming\n",
    "cohort = 'aging'\n",
    "\n",
    "# directories for initial setup\n",
    "wrk_dir = '/labshare/raph/datasets/adrd_neuro/brain_aging/phase1'\n",
    "quants_dir = f'{wrk_dir}/demux'\n",
    "results_dir = f'{wrk_dir}/results'\n",
    "\n",
    "# in files\n",
    "in_file = f'{quants_dir}/{cohort}.pegasus.leiden_085.subclustered.h5ad'\n",
    "\n",
    "# out files\n",
    "\n",
    "# constants\n",
    "DEBUG = True\n",
    "TESTING=False\n",
    "TEST_FEATURE_SIZE = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f30ba4",
   "metadata": {},
   "source": [
    "#### analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90886c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_anndata(data: AnnData, cell_name: str, type_name: str, \n",
    "                   region_name: str=None, reapply_filter: bool=True, \n",
    "                   min_cell_count: int=3, verbose: bool=False) -> AnnData:\n",
    "    if region_name is None:\n",
    "        this_data = data[(data.obs[type_name] == cell_name)].copy()\n",
    "    elif not region_name is None:\n",
    "        this_data = data[(data.obs['Brain_region'] == region_name) & \n",
    "                         (data.obs[type_name] == cell_name)].copy()     \n",
    "    shape_before = this_data.shape\n",
    "    if reapply_filter:\n",
    "        sc.pp.filter_genes(this_data, min_counts=min_cell_count)\n",
    "        sc.pp.filter_cells(this_data, min_counts=min_cell_count)\n",
    "        shape_after = this_data.shape\n",
    "    if verbose:\n",
    "        print(f'subset complete, shape before and after: {shape_before} {shape_after}')\n",
    "        print(this_data)\n",
    "    return this_data\n",
    "\n",
    "def scale_dataframe(this_df : DataFrame):\n",
    "    scaledX = MinMaxScaler().fit_transform(this_df)\n",
    "    scaled_df = DataFrame(data=scaledX, columns=this_df.columns, \n",
    "                          index=this_df.index) \n",
    "    return scaled_df\n",
    "\n",
    "def convert_ad_to_df(data: AnnData, young_age_limit: float=30.0, \n",
    "                     scale: bool=True, verbose: bool=False) -> DataFrame:\n",
    "    data_df = data.to_df()\n",
    "    if scale:\n",
    "        data_df = scale_dataframe(data_df)    \n",
    "    annots = data.obs[['Brain_region', 'Age','Age_group', 'pool_name', \n",
    "                       'Sample_id', 'Sex', 'donor_id']].copy()\n",
    "    annots['old'] = np.where((annots['Age'] > young_age_limit), 1, 0)\n",
    "    annots['female'] = np.where((annots['Sex'] == 'Female'), 1, 0)\n",
    "    this_df = None\n",
    "    if data_df.index.equals(annots.index):\n",
    "        this_df = concat([data_df, annots], axis='columns')\n",
    "        if verbose:\n",
    "            print(f'anndata to pandas df complete: {this_df.shape}')\n",
    "            print(this_df.shape)\n",
    "            display(this_df.head())\n",
    "    return this_df\n",
    "\n",
    "def feature_detected(feature_col, features: list=None, df: DataFrame=None, \n",
    "                     min_cell_count: int=3, min_sample_det_rate: float=0.5,\n",
    "                     verbose: bool=False):    \n",
    "    good_feature = True\n",
    "    if feature_col.name in features:\n",
    "        nz_df = feature_col[feature_col > 0]\n",
    "        ok_cnts = df.loc[nz_df.index].Sample_id.value_counts() > min_cell_count\n",
    "        ok_sample_cnt = ok_cnts.sum()\n",
    "        unique_sample_id_count = df.Sample_id.nunique()\n",
    "        good_feature = ok_sample_cnt / unique_sample_id_count >= min_sample_det_rate\n",
    "        if verbose:\n",
    "            print(feature_col.name, end=', ')\n",
    "            print(f'nz_df.shape = {nz_df.shape}', end=', ')\n",
    "            print(f'{ok_sample_cnt}/{unique_sample_id_count}', end=', ')\n",
    "            print(good_feature)\n",
    "    return good_feature\n",
    "\n",
    "def poorly_detected_features(features: list=None, df: DataFrame=None, \n",
    "                             verbose=False) -> list:\n",
    "    feature_detect_df = df.apply(feature_detected, features=features, df=df)\n",
    "    bad_features = feature_detect_df.loc[~feature_detect_df].index.to_list()\n",
    "    if verbose:\n",
    "        print(f'bad features counts is {len(bad_features)}')\n",
    "    return bad_features\n",
    "\n",
    "def glm_model(formula: str, df: DataFrame, use_tweedie: bool=True):\n",
    "    if use_tweedie:\n",
    "        model = smf.glm(formula=formula, data=df, \n",
    "                        family=sm.families.Tweedie(link=sm.families.links.log(), \n",
    "                                                   var_power=1.6, eql=True))\n",
    "    else:\n",
    "        model = smf.glm(formula=formula, data=df)\n",
    "    result = model.fit()\n",
    "    return result\n",
    "\n",
    "@jit(nopython=True)\n",
    "def compute_fold_change(intercept: float, coef: float) -> float:\n",
    "    if coef > 0:\n",
    "        fc = np.log2((intercept + coef)/intercept)\n",
    "    else:\n",
    "        fc = -np.log2(intercept/(intercept - abs(coef)))\n",
    "    return fc\n",
    "\n",
    "def compute_frmt_pb(df: DataFrame, feature: str) -> DataFrame:\n",
    "    ret_df = df[[feature, 'Sample_id']].groupby('Sample_id').mean()\n",
    "    ret_df = ret_df.merge(df[['Sample_id', 'pool_name', 'old', 'female']].drop_duplicates(), \n",
    "                          how='left', left_index=True, right_on='Sample_id')\n",
    "    return ret_df\n",
    "\n",
    "def glm_diff_expr_age(df: DataFrame, feature: str, verbose: bool=False) -> tuple:\n",
    "    dep_term = feature\n",
    "    indep_term = 'old'\n",
    "    this_formula = f'Q(\"{dep_term}\") ~ {indep_term} + C(pool_name) + female'\n",
    "    # just drop zeros \n",
    "    # try:\n",
    "    pb_df = compute_frmt_pb(df, feature)\n",
    "        # run GLM via statsmodel\n",
    "    result = glm_model(this_formula, pb_df)\n",
    "    fold_change = compute_fold_change(result.params['Intercept'], \n",
    "                                      result.params[indep_term])\n",
    "    ret_list = [dep_term, result.params['Intercept'], \n",
    "                result.params[indep_term], result.bse[indep_term], \n",
    "                result.tvalues[indep_term], result.pvalues[indep_term], \n",
    "                fold_change]\n",
    "    if verbose:\n",
    "        print(f'df shape {df.shape}')\n",
    "        print(f'non-zero df shape {pb_df.shape}')\n",
    "        print(result.summary())\n",
    "        print(['feature', 'intercept', 'coef', 'stderr', 'z', 'p-value', 'log2_fc'])\n",
    "        print(ret_list)\n",
    "#     except:\n",
    "# #         print(f'Caught Error for {dep_term}')\n",
    "#         ret_list = [dep_term] + [np.nan] * 6\n",
    "  \n",
    "    return ret_list\n",
    "\n",
    "def diffexp_group(data: AnnData, cell_name: str, result_type: str,\n",
    "                  min_cell_count: int=3, verbose: bool=False) -> DataFrame:\n",
    "    if verbose:\n",
    "        print('converting anndata to pandas df')        \n",
    "    type_df = convert_ad_to_df(data)\n",
    "    if verbose:\n",
    "        print(f'finding poorly detected features from cells x features {type_df.shape}')    \n",
    "    bad_features = poorly_detected_features(data.var.index.values, type_df)\n",
    "    type_clean_df = type_df.drop(columns=bad_features)\n",
    "    keep_features = set(data.var.index) & set(type_clean_df.columns)\n",
    "    type_clean_ad = data[:,list(keep_features)] \n",
    "    features_set = set(type_clean_ad.var.index) & set(type_clean_df.columns)\n",
    "    if len(features_set) > 0:\n",
    "        type_results = [glm_diff_expr_age(type_clean_df, feature) for feature in features_set]\n",
    "        results_df = DataFrame(data=type_results, \n",
    "                               columns=['feature', 'intercept', 'coef', \n",
    "                                        'stderr', 'z', 'p-value', 'log2_fc'])\n",
    "        results_df['tissue'] = cell_name\n",
    "        results_df['type'] = result_type\n",
    "        save_results(results_df, cell_name)\n",
    "    else:\n",
    "        print(f'no features left skipping: {cell_name}')\n",
    "    if verbose:\n",
    "        print(f'analyzed {len(features_set)} features')\n",
    "        print(f'done', end='. ')\n",
    "        \n",
    "def diffexp_group_wrapper(data: AnnData, cell_name: str, result_type: str):\n",
    "    diffexp_group(data, cell_name, result_type)\n",
    "\n",
    "def save_results(df: DataFrame, cell_name: str):\n",
    "    out_file = f'{results_dir}/{cell_name.replace(\" \", \"_\")}_glm_pb_age_diffs.csv'\n",
    "    df.to_csv(out_file, index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c37bc3-6ef9-4641-8706-2520647b6c8b",
   "metadata": {},
   "source": [
    "### load discovery cohort data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0761635d",
   "metadata": {},
   "source": [
    "#### read the anndata (h5ad) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996604d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adata = sc.read(in_file, cache=True)\n",
    "print(adata)\n",
    "if DEBUG:\n",
    "    display(adata.obs.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0521233a-93d5-4aa6-8b2f-c64cd124c9e3",
   "metadata": {},
   "source": [
    "##### find cell-types we won't use in analysis\n",
    "remove them, and then refilter genes based on cell count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30de512",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_uncertain = [x for x in adata.obs['new_anno'].unique().to_list() \n",
    "                   if 'uncertain' in x] + ['Astrocyte-GFAP-Hi']\n",
    "print(found_uncertain)\n",
    "adata = adata[~adata.obs['new_anno'].isin(found_uncertain ), :]\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03cc456-ab9f-4834-b447-150be0b1d07e",
   "metadata": {},
   "source": [
    "### get the lists of brain regions and broad cell types\n",
    "don't include broad cell-type 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8034601-30d5-4537-89b9-f12b8a6bfccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_cell_types = list(adata.obs.broad_celltype.unique())\n",
    "# broad_cell_types.remove('Other')\n",
    "print(len(broad_cell_types))\n",
    "print(broad_cell_types)\n",
    "brain_regions = list(adata.obs.Brain_region.unique())\n",
    "print(len(brain_regions))\n",
    "print(brain_regions)\n",
    "specific_celltypes = list(adata.obs.new_anno.unique())\n",
    "print(len(specific_celltypes))\n",
    "print(specific_celltypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20212b83",
   "metadata": {},
   "source": [
    "#### take a look at the cell counts by cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- all regions broad cell types ---')\n",
    "display(adata.obs.broad_celltype.value_counts())\n",
    "\n",
    "for brain_region in brain_regions:\n",
    "    this_adata = adata[adata.obs.Brain_region == brain_region]\n",
    "    print(f'--- {brain_region} ---')\n",
    "    display(this_adata.obs.broad_celltype.value_counts())\n",
    "    \n",
    "print('--- cluster specific cell-types ---')\n",
    "display(adata.obs.new_anno.value_counts())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e59b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.pl.umap(adata, color=[celltype_obs_feature], legend_loc='on data')\n",
    "with rc_context({'figure.figsize': (9, 9)}):\n",
    "    sc.pl.umap(adata, color=['new_anno'], legend_loc='on data', \n",
    "               add_outline=True, legend_fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf42aef",
   "metadata": {},
   "source": [
    "### if testing notebooks for debugging purpose subset the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227c7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TESTING:\n",
    "    features = random.sample(list(adata.var.index.values), TEST_FEATURE_SIZE)\n",
    "    adata = adata[:,features]\n",
    "    print(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8cf910",
   "metadata": {},
   "source": [
    "### for each cell-type compute the differential expression\n",
    "\n",
    "using pseudobulk and GLM\n",
    "\n",
    "parallelized by cell-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcdaa3c-782b-4d13-b4d2-3bc11499ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cmds = {}\n",
    "print('### broad cell-types without regard for region')\n",
    "for cell_type in broad_cell_types:\n",
    "    cell_name = f'all_{cell_type}'\n",
    "    print(f'\\n--- {cell_name}')\n",
    "    this_type = 'broad_celltype'\n",
    "    adata_sub = subset_anndata(adata, cell_type, 'broad_celltype')\n",
    "    # diffexp_group(adata_sub, cell_name, this_type, verbose=True)\n",
    "    p = Process(target=diffexp_group_wrapper,args=(adata_sub, cell_name, this_type))\n",
    "    p.start()\n",
    "    # Append process and key to keep track\n",
    "    cmds[cell_name] = p       \n",
    "    \n",
    "print('\\n### broad cell-types per regions')\n",
    "for brain_region in brain_regions:   \n",
    "    for cell_type in broad_cell_types:\n",
    "        cell_name = f'{brain_region}_{cell_type}'\n",
    "        print(f'--- {cell_name}')\n",
    "        this_type = 'region_broad_celltype'\n",
    "        adata_sub = subset_anndata(adata, cell_type, 'broad_celltype', brain_region)\n",
    "#         diffexp_group(adata_sub, cell_name, this_type, verbose=True)\n",
    "        p = Process(target=diffexp_group_wrapper,args=(adata_sub, cell_name, this_type))\n",
    "        p.start()\n",
    "        # Append process and key to keep track\n",
    "        cmds[cell_name] = p\n",
    "        \n",
    "print('\\n### cluster specific cell-types')        \n",
    "for cell_type in specific_celltypes:\n",
    "    cell_name = cell_type\n",
    "    this_type = 'specific_celltype'\n",
    "    adata_sub = subset_anndata(adata, cell_type, 'new_anno')\n",
    "    print(f'--- {cell_name}')    \n",
    "#     diffexp_group(adata_sub, cell_name, this_type, verbose=True)\n",
    "    p = Process(target=diffexp_group_wrapper,args=(adata_sub, cell_name, this_type))\n",
    "    p.start()\n",
    "    # Append process and key to keep track\n",
    "    cmds[cell_name] = p\n",
    "\n",
    "# Wait for all processes to finish\n",
    "for key, p in cmds.items():\n",
    "    p.join()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ade5b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
